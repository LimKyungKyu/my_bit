github.com/AlexeyAB/darknet 참고.
위 깃헙에서 제공하는 darknet을 사용했음.

- yolov3 모델로 custom object를 학습 시킬 예정. (사람, 개, 불)
우선 학습 시킬 image 및 annotation 파일이 필요함.
(annotation file은 각 image 당 box 정보에 대한 label로서 
<class> <x_center> <y_center> <width> <height> 로 구성 됨)

- annotation 파일 획득 방법.
1. yolo-mark를 통해 (github.com/AlexeyAB/Yolo_mark) image로 부터 생성.
2. coco dataset을 다운받으면 image 파일들이 있고 각 annotation 정보가 적힌 json 파일이 있음.
   json 파일을 참고하여 annotation 정보를 획득할 수 있게 해주는 api를 사용하여 획득.

우리는 사람, 개 에대한 image 및 annotation은 coco dataset에서, 불은 인터넷으로 부터 
200장의 image를 구해 yolo-mark를 사용하여 annotation 생성.

이제 학습시킬 data도 있으니 학습 시켜보자.

1. 학습시킬 모델의 cfg파일을 yolo-obj.cfg로 복사. (yolov3.cfg 를 복사하여 yolo-obj.cfg 생성)
  그리고 안에 내용을 아래와 같이 수정
  batch=64
  subdivisions=8 # (혹시 학습 중 memory 부족해서 error가 난다면 batch를 32로 줄이던지 subdivision을 16 또는 32로 늘리면됨)
  max_batches=6000  # (max_batches 는 class갯수 * 2000, 우리는 3개이므로 6000)
  steps=4800,5400  # (steps 값은 max_batches의 80%, 90% 값을 순서대로 적어줌)

  그리고 [yolo] 레이어 및 [yolo] 레이어 바로 전 [convolutional] 레이어 값을 수정해야함
  [yolo] 레이어의 classes 값을 변경 ([yolo] 레이어는 3개임. 610, 696, 783 라인)
  classes=3 # (class 갯수)

  [yolo] 레이어 전 [convolutional] 레이어의 filters 값을 변경
  filters=24 # (filters = (classes + 5 ) * 3 으로 계산)

2. obj.names 파일을 생성해서 분류할 class 이름을 적음 (yolo-mark를 사용했다면 이미 있을거임, 복사하기)
>> obj.names 내용 예시
  person
  dog
  fire

3. obj.data 파일 생성 (yolo-mark를 사용했다면 있을거임, 복사)
>> obj.data 내용 예시
  classes= 3
  train  = data/train.txt
  valid  = data/train.txt
  names = data/obj.names
  backup = backup/

4. image 및 annotation 파일들을 darknet\x64\data\img 폴더에 넣기
  (위 경로는 windows 버전에서의 경로이고 linux 경우 darknet\data\img, 이하 windows 경로로 설명)

5. train.txt 파일 생성 (yolo-mark 사용했다면 있을거임, 복사. 이 파일은 image 경로 적혀있음)
>> train.txt. 내용 예시
  data/img/img1.jpg
  data/img/img2.jpg
  data/img/img3.jpg
  ...

  위 파일을 darknet\x64\data 에 복사

6. pre-train 된 weight를 아래 주소에서 다운받아 darknet\x64 경로에 복사 (transfer learning)
  https://pjreddie.com/media/files/darknet53.conv.74

7. darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 명령을 통해 학습 수행


* 전이학습(transfer learning)
학습 데이터가 고 해상도의 컬러 이미지라면 CNN 및 FCL 를 거쳐 학습시키면 굉장히 오랜 시간 걸림.

잘 훈련된 사전학습(pre-trained)된 CNN 모델이 있다면 이미 학습 되어 있는 weight, bias 등의 값을 
수정(tuning)해서 사용함으로서, 임의의 값으로 초기화된 파라미터를 처음부터 학습시키는 것에 비해
소요시간을 획기적으로 줄일 수 있음. 또한 data가 부족하더라도 이미 이전 모델에서 풍부한 데이터로
학습하였기 때문에 효과적으로 학습 가능.

이미 학습되어 있는 (pre-trained) 모델의 weight와 bias 등을 자신의 데이터로 전달하여 빠르게 학습. 
ResNet GoogleNet 등 유명한 모델을 이용하여 원하는 데이터에 미세 조정(Fine tuning)으로 
학습시키는 방법. 기존 모델의 layer도 재사용.


